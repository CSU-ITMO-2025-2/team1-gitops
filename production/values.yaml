global:
  configMapName: "" # Будет использовано значение по умолчанию {{ .Release.Name }}-config
  secretName: "team-1-secrets" # Имя существующего secret. Если пусто, будет использовано значение по умолчанию {{ .Release.Name }}-secrets
  rbac:
    enabled: true # Set to true to enable RBAC-based secret isolation (can be overridden in subcharts)
# Image pull secrets для GHCR
imagePullSecrets:
  - name: ghcr-secret
# Image configurations
# Note: replicaCount управляется HPA для coreApi/frontend и KEDA для workers
image:
  authService:
    repository: ghcr.io/csu-itmo-2025-2/team1-auth-service
    tag: latest
    pullPolicy: Always
  coreApi:
    repository: ghcr.io/csu-itmo-2025-2/team1-core-api
    tag: sha-1c5cb2d
    pullPolicy: Always
  frontend:
    repository: ghcr.io/csu-itmo-2025-2/team1-frontend
    tag: sha-1c5cb2d
    pullPolicy: Always
  resumeWorker:
    repository: ghcr.io/csu-itmo-2025-2/team1-resume-evaluation-worker
    tag: sha-1c5cb2d
    pullPolicy: Always
  jobDescrWorker:
    repository: ghcr.io/csu-itmo-2025-2/team1-job-description-worker
    tag: sha-1c5cb2d
    pullPolicy: Always
  questionWorker:
    repository: ghcr.io/csu-itmo-2025-2/team1-question-generation-worker
    tag: sha-1c5cb2d
    pullPolicy: Always
# Resource requests/limits based on actual usage metrics
# IMPORTANT: Current values are from IDLE state (no load)
# Actual idle usage: Core API (2m CPU, 81Mi RAM), Frontend (1m CPU, 200Mi RAM)
# TODO: Adjust after load testing or monitoring production traffic
resources:
  coreApi:
    requests:
      cpu: "100m" # Conservative: allows 50x growth from idle
      memory: "256Mi" # Conservative: allows 3x growth (recommend monitoring)
    limits:
      cpu: "500m" # Allow bursts during high load
      memory: "512Mi" # Original limit maintained
  frontend:
    requests:
      cpu: "50m" # Conservative: Streamlit can be heavier under load
      memory: "256Mi" # Already using 200Mi idle, needs headroom
    limits:
      cpu: "200m" # Allow bursts
      memory: "512Mi" # Higher limit for peak usage
# Autoscaling configuration
autoscaling:
  coreApi:
    enabled: false # Отключено: core-api использует Argo Rollout (не поддерживает HPA)
    minReplicas: 1
    maxReplicas: 5
    targetMemoryUtilization: 70
  frontend:
    enabled: true
    minReplicas: 1
    maxReplicas: 5
    targetMemoryUtilization: 70
rabbitmq:
  image: rabbitmq:3.13-management-alpine
  username: guest
  password: ""
  vhost: "/"
  port: 5672
  uiPort: 15672
postgres:
  image: postgres:16
  username: postgres
  password: ""
  db: hr_assist
  port: 5432
ingress:
  enabled: true
  host: ""
  className: nginx
  tls: false
env:
  openaiModelName: "gpt-4o-mini"
  openaiApiBase: "https://api.openai.com/v1"
  logLevel: INFO
  # Proxy configuration for external API access via Squid
  HTTP_PROXY: "http://109.120.129.63:48011"
  HTTPS_PROXY: "http://109.120.129.63:48011"
  NO_PROXY: "localhost,127.0.0.1,.svc,.cluster.local,team1-project-rabbitmq,team1-project-postgres"
  # PostgreSQL (внутренний)
  POSTGRES_HOST: "team1-project-postgres"
  POSTGRES_PORT: "5432"
  POSTGRES_DB: "hr_assist"
  POSTGRES_USER: "postgres"
  # RabbitMQ (внутренний)
  RABBITMQ_DEFAULT_HOST: "team1-project-rabbitmq"
  RABBITMQ_PORT: "5672"
secrets:
  useExternal: True # используем Vault
  useExisting: False # true для тестов
  existingSecretName: "hr-assist-secrets"
  # Используем существующий SecretStore vault-team1 (создан администратором)
  # Vault конфигурация не требуется
# RBAC Configuration
rbac:
  enabled: true # Set to true to enable RBAC-based secret isolation
job-description-service:
  image:
    repository: ghcr.io/csu-itmo-2025-2/team1-job-description-worker
    tag: sha-1c5cb2d
    pullPolicy: Always
  # replicaCount управляется KEDA
  configMap:
    name: ""
  secret:
    name: ""
  # KEDA autoscaling configuration (queue-based)
  autoscaling:
    enabled: true # Включено для production
    minReplicaCount: 1
    maxReplicaCount: 5
    queueName: "job_description_queue"
    queueLength: 10 # Scale 1 replica per 10 messages in queue
    rabbitmqHost: "" # Will use RabbitMQ service name from parent chart
question-generation-service:
  image:
    repository: ghcr.io/csu-itmo-2025-2/team1-question-generation-worker
    tag: sha-1c5cb2d
    pullPolicy: Always
  # replicaCount управляется KEDA
  configMap:
    name: ""
  secret:
    name: ""
  # KEDA autoscaling configuration (queue-based)
  autoscaling:
    enabled: true # Включено для production
    minReplicaCount: 1
    maxReplicaCount: 5
    queueName: "question_generation_queue"
    queueLength: 10 # Scale 1 replica per 10 messages in queue
    rabbitmqHost: "" # Will use RabbitMQ service name from parent chart
resume-evaluation-service:
  image:
    repository: ghcr.io/csu-itmo-2025-2/team1-resume-evaluation-worker
    tag: sha-1c5cb2d
    pullPolicy: Always
  # replicaCount управляется KEDA
  configMap:
    name: ""
  secret:
    name: ""
  # KEDA autoscaling configuration (queue-based)
  autoscaling:
    enabled: true # Включено для production
    minReplicaCount: 1
    maxReplicaCount: 5
    queueName: "resume_evaluation_queue"
    queueLength: 10 # Scale 1 replica per 10 messages in queue
    rabbitmqHost: "" # Will use RabbitMQ service name from parent chart
networkPolicy:
  enabled: true
